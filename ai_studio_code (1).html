<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Advanced AI Vision System</title>
    
    <!-- MediaPipe Dependencies -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js" crossorigin="anonymous"></script>

    <style>
        :root {
            --primary: #00f2ff;
            --secondary: #ff0055;
            --bg: #0d1117;
            --glass: rgba(13, 17, 23, 0.85);
        }

        body {
            margin: 0;
            padding: 0;
            background-color: var(--bg);
            color: white;
            font-family: 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }

        /* Container for Video and Canvas */
        .vision-container {
            position: relative;
            width: 100%;
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        video {
            position: absolute;
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1); /* Mirror effect */
            z-index: 1;
        }

        canvas {
            position: absolute;
            width: 100%;
            height: 100%;
            object-fit: cover;
            z-index: 2;
            transform: scaleX(-1); /* Mirror match */
        }

        /* HUD Overlay */
        .hud {
            position: absolute;
            top: 20px;
            left: 20px;
            z-index: 3;
            background: var(--glass);
            padding: 15px;
            border-radius: 12px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            min-width: 200px;
            box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.37);
        }

        .hud h1 {
            font-size: 1.2rem;
            margin: 0 0 10px 0;
            color: var(--primary);
            text-transform: uppercase;
            letter-spacing: 2px;
        }

        .stat-row {
            display: flex;
            justify-content: space-between;
            margin-bottom: 5px;
            font-size: 0.9rem;
        }

        .stat-label { color: #aaa; }
        .stat-value { font-weight: bold; color: white; }

        .controls {
            position: absolute;
            bottom: 30px;
            z-index: 3;
            display: flex;
            gap: 15px;
        }

        button {
            background: var(--primary);
            border: none;
            padding: 12px 24px;
            border-radius: 30px;
            color: #000;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.2s;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        button:hover { transform: scale(1.05); box-shadow: 0 0 15px var(--primary); }
        button.stop { background: var(--secondary); color: white; }
        
        .loading {
            position: absolute;
            z-index: 10;
            background: rgba(0,0,0,0.9);
            width: 100%;
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
            flex-direction: column;
        }

        .spinner {
            width: 50px;
            height: 50px;
            border: 5px solid #333;
            border-top: 5px solid var(--primary);
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }
        
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body>

    <div class="loading" id="loadingScreen">
        <div class="spinner"></div>
        <p style="margin-top: 20px;">Initializing AI Models...</p>
    </div>

    <div class="vision-container">
        <video id="inputVideo" playsinline></video>
        <canvas id="outputCanvas"></canvas>
        
        <div class="hud">
            <h1>AI Vision v1.0</h1>
            <div class="stat-row">
                <span class="stat-label">System:</span>
                <span class="stat-value" id="statusText">Active</span>
            </div>
            <div class="stat-row">
                <span class="stat-label">Hands Detected:</span>
                <span class="stat-value" id="handCount">0</span>
            </div>
            <div class="stat-row">
                <span class="stat-label">Gesture:</span>
                <span class="stat-value" id="gestureText" style="color: var(--primary)">None</span>
            </div>
            <div class="stat-row">
                <span class="stat-label">Finger Count:</span>
                <span class="stat-value" id="fingerCountText">0</span>
            </div>
            <div class="stat-row">
                <span class="stat-label">Pose:</span>
                <span class="stat-value" id="poseStatus">Searching...</span>
            </div>
            <div class="stat-row">
                <span class="stat-label">FPS:</span>
                <span class="stat-value" id="fpsText">0</span>
            </div>
        </div>

        <div class="controls">
            <button id="toggleBtn">Pause System</button>
        </div>
    </div>

    <script>
        // --- Configuration ---
        const VIDEO_Element = document.getElementById('inputVideo');
        const CANVAS_Element = document.getElementById('outputCanvas');
        const CTX = CANVAS_Element.getContext('2d');
        const LOADING = document.getElementById('loadingScreen');
        
        // UI References
        const uiHandCount = document.getElementById('handCount');
        const uiGesture = document.getElementById('gestureText');
        const uiFingerCount = document.getElementById('fingerCountText');
        const uiPose = document.getElementById('poseStatus');
        const uiFps = document.getElementById('fpsText');
        const btnToggle = document.getElementById('toggleBtn');

        let isRunning = true;
        let lastFrameTime = 0;
        
        // Wave Detection History
        const HAND_HISTORY = new Map(); // Store previous x-coordinates for wave detection
        const WAVE_THRESHOLD = 5; // Frames to track
        const MOVEMENT_THRESHOLD = 0.02; // Min movement to count as a "swing"

        // --- Initialization ---

        // 1. Setup MediaPipe Hands
        const hands = new Hands({locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
        }});
        
        hands.setOptions({
            maxNumHands: 2,
            modelComplexity: 1, // 0: Lite, 1: Full
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });

        // 2. Setup MediaPipe Pose
        const pose = new Pose({locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`;
        }});
        
        pose.setOptions({
            modelComplexity: 1,
            smoothLandmarks: true,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });

        // --- Logic: Finger Counting & Gesture Recognition ---

        function countFingers(landmarks) {
            // Landmark Indices:
            // Thumb: 1-4, Index: 5-8, Middle: 9-12, Ring: 13-16, Pinky: 17-20
            const tips = [4, 8, 12, 16, 20];
            const pips = [3, 6, 10, 14, 18]; // Knuckles/Joints for comparison
            
            let count = 0;
            let fingersState = [0, 0, 0, 0, 0]; // 0: Folded, 1: Open

            // 1. Check Thumb (Compare X for side-to-side movement or check angle)
            // Simple logic: Is tip further to the outside than the IP joint?
            // Note: Depends on hand usage (Left vs Right). 
            // Generic robust check: Compare tip distance to pinky knuckle vs IP distance.
            // Here we use a simplified X-check assuming palm faces camera.
            
            // Determine Handedness (Left/Right) roughly by x-coord of wrist vs thumb cmc (landmark 1)
            // Or just check if thumb tip x is < or > than joint x depending on relative position to index finger.
            const thumbTip = landmarks[4];
            const thumbIP = landmarks[3];
            const indexMCP = landmarks[5];

            // If thumb tip is further away from the palm center (simulated by Index MCP X)
            // We calculate distance. 
            // Simpler: Check if thumb tip x is to the 'outside' of the hand relative to the IP joint.
            // For this demo, we'll use a vector check against the index finger base.
            if (Math.abs(thumbTip.x - indexMCP.x) > Math.abs(thumbIP.x - indexMCP.x)) {
                count++;
                fingersState[0] = 1;
            }

            // 2. Check Other 4 Fingers (Y-axis check)
            // If Tip Y < PIP Y (remember Y increases downwards in screen coords), finger is raised.
            for (let i = 1; i < 5; i++) {
                if (landmarks[tips[i]].y < landmarks[pips[i]].y) {
                    count++;
                    fingersState[i] = 1;
                }
            }

            return { count, state: fingersState };
        }

        function detectGesture(fingersState, handId, landmarks) {
            const [thumb, index, middle, ring, pinky] = fingersState;
            const total = fingersState.reduce((a, b) => a + b, 0);

            // Logic: Wave Detection (Temporal)
            // We need to check history for side-to-side movement
            let isWaving = false;
            const wristX = landmarks[0].x;
            
            if (!HAND_HISTORY.has(handId)) {
                HAND_HISTORY.set(handId, []);
            }
            const history = HAND_HISTORY.get(handId);
            history.push(wristX);
            if (history.length > 15) history.shift(); // Keep last 15 frames

            // Check oscillation: Look for changing directions
            if (history.length > 10 && total === 5) {
                // Calculate deltas
                let directionChanges = 0;
                let currentDir = 0; // -1 Left, 1 Right
                
                for(let i = 1; i < history.length; i++) {
                    const diff = history[i] - history[i-1];
                    if (Math.abs(diff) > 0.005) { // Noise filter
                        const newDir = diff > 0 ? 1 : -1;
                        if (currentDir !== 0 && newDir !== currentDir) {
                            directionChanges++;
                        }
                        currentDir = newDir;
                    }
                }
                
                if (directionChanges >= 2) isWaving = true;
            }

            // Classification
            if (isWaving) return "Wave ðŸ‘‹";
            
            // Stop: All fingers open
            if (total === 5) return "Stop âœ‹";

            // Thumbs Up: Thumb open, others closed
            // Also check thumb tip is above thumb IP (y-axis)
            if (thumb === 1 && index === 0 && middle === 0 && ring === 0 && pinky === 0) {
                if (landmarks[4].y < landmarks[3].y) { // Ensure thumb is pointing up
                    return "Thumbs Up ðŸ‘";
                }
            }

            // Peace
            if (index === 1 && middle === 1 && ring === 0 && pinky === 0) return "Peace âœŒï¸";

            // Fist
            if (total === 0) return "Fist âœŠ";

            return null;
        }

        // --- Main Rendering Loop ---

        // We use a custom loop to feed data into MediaPipe
        async function onFrame() {
            if (!isRunning) {
                requestAnimationFrame(onFrame);
                return;
            }

            // Calculate FPS
            const now = performance.now();
            const fps = 1000 / (now - lastFrameTime);
            lastFrameTime = now;
            if (now % 10 === 0) uiFps.innerText = Math.round(fps); // Update GUI occasionally

            // Prepare Canvas
            CTX.save();
            CTX.clearRect(0, 0, CANVAS_Element.width, CANVAS_Element.height);
            
            // 1. Send video frame to Pose
            // Note: Running both sequentially every frame is heavy.
            // Optimization: Run Pose and Hands on alternative frames if FPS drops, 
            // but for "Advanced System" we try both.
            
            await pose.send({image: VIDEO_Element});
            await hands.send({image: VIDEO_Element});

            CTX.restore();
            requestAnimationFrame(onFrame);
        }

        // --- Processing Results ---

        // Handle Pose Results
        pose.onResults((results) => {
            if (!results.poseLandmarks) {
                uiPose.innerText = "Not Detected";
                uiPose.style.color = "red";
                return;
            }
            uiPose.innerText = "Tracking Active";
            uiPose.style.color = "var(--primary)";

            // Draw Skeleton
            drawConnectors(CTX, results.poseLandmarks, POSE_CONNECTIONS, 
                          {color: 'rgba(0, 242, 255, 0.5)', lineWidth: 2});
            drawLandmarks(CTX, results.poseLandmarks, 
                          {color: '#ff0055', lineWidth: 1, radius: 3});
        });

        // Handle Hand Results
        hands.onResults((results) => {
            uiHandCount.innerText = results.multiHandLandmarks.length;
            
            let totalFingers = 0;
            let dominantGesture = "None";

            if (results.multiHandLandmarks) {
                for (const [index, landmarks] of results.multiHandLandmarks.entries()) {
                    // Draw Connectors
                    drawConnectors(CTX, landmarks, HAND_CONNECTIONS, {color: '#00f2ff', lineWidth: 3});
                    drawLandmarks(CTX, landmarks, {color: '#ffffff', lineWidth: 1, radius: 4});

                    // Logic
                    const { count, state } = countFingers(landmarks);
                    totalFingers += count;

                    // Hand ID logic (simple index based)
                    const gesture = detectGesture(state, index, landmarks);
                    
                    if (gesture) dominantGesture = gesture;

                    // Draw Text on Canvas near Wrist
                    const wrist = landmarks[0];
                    const x = wrist.x * CANVAS_Element.width;
                    const y = wrist.y * CANVAS_Element.height;

                    CTX.fillStyle = "rgba(0,0,0,0.7)";
                    CTX.roundRect(x - 40, y + 10, 80, 40, 5);
                    CTX.fill();
                    
                    CTX.fillStyle = "#00f2ff";
                    CTX.font = "bold 16px sans-serif";
                    CTX.textAlign = "center";
                    CTX.fillText(`Fingers: ${count}`, x, y + 30);
                    
                    if (gesture) {
                        CTX.fillStyle = "#ff0055";
                        CTX.fillText(gesture, x, y - 10);
                    }
                }
            }
            
            // Update UI
            uiFingerCount.innerText = totalFingers;
            if (dominantGesture !== "None") {
                uiGesture.innerText = dominantGesture;
            }
        });

        // --- Camera Setup ---

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: {
                    facingMode: 'environment', // Rear camera on mobile
                    width: { ideal: 1280 },
                    height: { ideal: 720 }
                },
                audio: false
            });

            VIDEO_Element.srcObject = stream;
            
            return new Promise((resolve) => {
                VIDEO_Element.onloadedmetadata = () => {
                    VIDEO_Element.play();
                    // Resize Canvas to match Video
                    CANVAS_Element.width = VIDEO_Element.videoWidth;
                    CANVAS_Element.height = VIDEO_Element.videoHeight;
                    resolve();
                };
            });
        }

        // --- App Entry Point ---

        (async function init() {
            try {
                await setupCamera();
                // Wait a moment for MediaPipe to initialize internally
                setTimeout(() => {
                    LOADING.style.display = 'none';
                    onFrame();
                }, 2000);
            } catch (e) {
                alert("Error accessing camera: " + e.message);
                LOADING.innerHTML = "<p>Camera Access Denied</p>";
            }
        })();

        // --- Controls ---
        btnToggle.addEventListener('click', () => {
            isRunning = !isRunning;
            if (isRunning) {
                btnToggle.innerText = "Pause System";
                btnToggle.classList.remove('stop');
                onFrame();
            } else {
                btnToggle.innerText = "Resume";
                btnToggle.classList.add('stop');
            }
        });

        // Resize handler
        window.addEventListener('resize', () => {
             // Optional: specific resize logic if canvas loses sync with video
        });

    </script>
</body>
</html>